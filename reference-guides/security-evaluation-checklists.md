# Security Evaluation Checklists

A security checklist helps ensure thorough, consistent, and reproducible evaluation of LLM systems. Whether youâ€™re conducting a red team assessment, securing a new deployment, or hardening a plugin, a checklist provides **coverage** across multiple dimensions â€” from prompt injection to model supply chain to inference abuse.

This page includes **modular, actionable checklists** for different layers of LLM infrastructure.

***

## ğŸ§© General LLM Deployment Checklist

âœ… = Required\
ğŸŸ¡ = Recommended\
â¬œ = Optional (context dependent)

| Category                | Checkpoint                                         | Status |
| ----------------------- | -------------------------------------------------- | ------ |
| Authentication          | API keys or tokens required for all LLM access     | âœ…      |
| Rate Limiting           | Per-user/token request cap enforced                | âœ…      |
| Logging                 | Prompt/response pairs logged with session metadata | âœ…      |
| Token Budgeting         | Max input/output token caps per component          | ğŸŸ¡     |
| Guard Prompts           | Safety/system prompts injected consistently        | âœ…      |
| Output Validation       | Regex / toxicity / type-checking applied           | âœ…      |
| Prompt Isolation        | System vs user input boundaries maintained         | âœ…      |
| Canary Prompts          | Canary strings inserted and monitored              | ğŸŸ¡     |
| Language/Encoding Norms | Non-ASCII/RTL/malformed input filtered             | ğŸŸ¡     |

***

## ğŸ’¬ Prompt Injection Checklist

| Test Case                                     | Status |
| --------------------------------------------- | ------ |
| Direct override prompt (`Ignore above...`)    | âœ…      |
| Indirect roleplay prompt (`Letâ€™s pretend...`) | âœ…      |
| Nested prompt inside RAG content              | âœ…      |
| Input sanitization bypass test                | âœ…      |
| Context boundary test (user/system mix)       | âœ…      |
| Emoji / Unicode / zero-width evasion          | ğŸŸ¡     |

***

## ğŸ”§ Tool Use / Plugin Security

| Plugin Security Area                      | Status |
| ----------------------------------------- | ------ |
| Schema validation of tool calls           | âœ…      |
| Parameter length/type enforcement         | âœ…      |
| Tools whitelisted per role/user           | âœ…      |
| Output from tools filtered or escaped     | âœ…      |
| No shell / file / exec tools exposed      | âœ…      |
| Canary calls (e.g., fake tools) monitored | ğŸŸ¡     |

***

## ğŸ” Inference Abuse Detection

| Behavior                                    | Monitoring Status |
| ------------------------------------------- | ----------------- |
| Token bloat attempts (long prompt flooding) | âœ…                 |
| Model echo leaks (repeats system prompt)    | âœ…                 |
| Unexpected tool calls / fallback chains     | âœ…                 |
| Known jailbreak signature output            | âœ…                 |
| Prompt reuse across sessions                | ğŸŸ¡                |

***

## ğŸ§± Supply Chain + Serialization

| Risk Area                                   | Status          |
| ------------------------------------------- | --------------- |
| Pickle or torch.load() model loading        | Audited/Blocked |
| Model artifact signatures (SHA256)          | âœ…               |
| Third-party model dependencies verified     | âœ…               |
| Plugin code sandboxed or containerized      | âœ…               |
| Model card reviewed for limitations         | âœ…               |
| Cache/memory sharing disabled between users | âœ…               |

***

## ğŸ§  Red Team / Evaluation

| Activity                                      | Completed |
| --------------------------------------------- | --------- |
| PromptBench or Garak alignment testing        | âœ…         |
| PyRIT persona + injection attack simulation   | âœ…         |
| RAG poisoning or document injection tested    | âœ…         |
| Canary embedding surfaced intentionally       | âœ…         |
| Adversarial input evaluation (toxicity, bias) | âœ…         |
| Automated harness fuzzing of input/output     | ğŸŸ¡        |

***

## ğŸ“Œ Summary

You canâ€™t secure what you donâ€™t test.\
You canâ€™t test what you donâ€™t track.\
These checklists are your blueprint for **structured red teaming**, **system hardening**, and **repeatable AI security reviews**.
