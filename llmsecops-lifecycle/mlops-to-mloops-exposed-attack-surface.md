---
description: >-
  Lessons learned on securing ML platforms from real-world attacks and
  operational mistakes (Black Hat USA 2024).
---

# MLOps to MLOops: Exposed Attack Surface

## üß© MLOps vs MLOops: What's the Risk?

**MLOps** typically involves automation and monitoring for ML pipelines‚Äîdata ingestion, model training, deployment, and monitoring.\
**MLOops** ("loops" or repeated mistakes) occur when misconfigured MLOps pipelines enable vulnerabilities, exploits, or continuous compromise.

Attackers exploit weak governance, insufficient monitoring, and open interfaces in ML pipelines, turning automated workflows into continuous attack vectors.

***

## üö® Common Security Failures in ML Pipelines

#### 1. **Over-Permissive Data Access**

* Data engineers granting blanket access for convenience
* Excessive AWS IAM or GCP roles (`ml.developer` role with full `storage.buckets.*` permissions)

#### 2. **Unsecured Training Pipelines**

* Public-facing endpoints (`kubeflow`, `mlflow`) without authentication
* Container images containing hardcoded credentials or secrets

#### 3. **Model Registry Misconfigurations**

* Publicly accessible MLFlow registry, exposing models for download
* Absence of audit logging for registry activity

#### 4. **Weakness in Model Deployment**

* Lack of drift or anomaly detection in prod
* No rate limiting, exposing inference endpoints to flooding

***

## üîç Case Study: Model Poisoning via Open Pipeline

Attack Scenario:

* Attacker identifies public Kubeflow endpoint (via Shodan).
* Injects poison data into the pipeline dataset.
* Poisoned data affects automated retraining, pushing compromised model to production.

Mitigation:

* Strict pipeline ACLs, RBAC enforcement, IAM role minimization
* Pre-processing hooks validating dataset provenance (checksum verification, source tagging)

***

## ‚öîÔ∏è Practical Exploit Scenarios

| Attack Surface         | Exploit Scenario                                           | Mitigation                                 |
| ---------------------- | ---------------------------------------------------------- | ------------------------------------------ |
| MLFlow Tracking Server | Exposed model storage on public URL                        | IP whitelisting, OAuth2                    |
| Container Registry     | Public containers with embedded secrets                    | Pre-scan images, secret rotation           |
| Training Jobs          | Poisoned input files from unsecured S3/GCS buckets         | Signed data artifacts, provenance tracking |
| Real-time Inference    | Data leakage via prompt injection in OpenAI-compatible API | Input sanitization, prompt firewalling     |

***

## üõ°Ô∏è LLMSecOps Best Practices Checklist

**Secure Access Management**

* [ ] Enforce least privilege IAM roles for pipeline tasks
* [ ] Regularly rotate API keys and container registry credentials

**Pipeline Integrity**

* [ ] Validate and sign data inputs and training datasets
* [ ] Implement automated checks for poisoned data (entropy scoring, anomaly detection)

**Registry & Model Security**

* [ ] Enforce private access to model registry endpoints
* [ ] Enable audit logging & access tracking on registry operations

**Real-time & Inference Protection**

* [ ] Deploy prompt firewalls for inference endpoints
* [ ] Configure real-time drift & anomaly detection alerts

***

## üìå Lessons Learned

* Unsecured automation multiplies risk exponentially (from one breach to continuous compromise).
* Strong governance, IAM discipline, and secure-by-default pipeline templates are essential.
* Continuous security monitoring & anomaly detection transform risky MLOps back into robust, secure operations.

***

üìö **See Also**

* Guardrails, Moderation APIs, and Filtering
* LLMSecOps Lifecycle
